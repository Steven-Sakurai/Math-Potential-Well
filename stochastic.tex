\documentclass[a4paper, 11pt]{article}
\usepackage{indentfirst}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage[]{braket}
\title{\textbf{Stochastic Analysis}}
\author{Steven Shen}
\begin{document}
\maketitle

\section{Foundation}
A stochastic process is a collection of $R.V.$: $X = \{X_t; 0 \leq t < \infty\}$ on sample space $(\Omega, \mathcal{F})$, which take values in a second measurable state space $(\mathcal{R}^d, \mathcal{B}(\mathcal{R}^d))$.

\subsection{Understanding $\sigma-algebra$}

\subsection{Filtration}
A non-decreasing family $\{ \mathcal{F}_t; t \geq 0 \}$ of $sub-\sigma-field$ of $\mathcal{F}$: $\mathcal{F}_s \subseteq \mathcal{F}_t \subseteq \mathcal{F}$ for $0 \leq s < t < \infty$. Set $\mathcal{F}_{\infty} = \sigma(\bigcup_{t \geq 0}\mathcal{F}_t)$.\\
\indent Given a process $X(t)$, the simplest choice of a filtration is $\mathcal{F}_t ^X = \sigma(X_s; 0 \leq s \leq t)$.

\subsection{Conditional Expectation}
$\mathbb{E}[X|\mathcal{G}]$ is the unique random variable that satisfies:
\begin{enumerate}
	\item $\mathbb{E}[X|\mathcal{G}]$ is $\mathcal{G}-measurable$
	\item $\int_A \mathbb{E}[X|\mathcal{G}](w) d\mathbb{P}(w) = \int_A X(w) d\mathbb{P}(w)$, for all $A \in \mathcal{G}$ \\
	(alternative expression: $\forall A \in \mathcal{G}, \mathbb{E}[\mathbb{E}[\mathbbm{1}_{A}X|\mathcal{G}]] = \mathbb{E}[\mathbbm{1}_{A}X]$)
\end{enumerate}
\indent $P.S.$: a very useful thing to remember: $\mathbb{P}(A) = \mathbb{E}\mathbbm{1}_{A}$.

\subsection{Stopping Times}
Consider a measurable space $(\Omega, \mathcal{F})$ equipped with a filtration $\{ \mathcal{F}_t \}$. A random time $T$ is a stopping time w.r.t. that filtration, if the event $\{ T \leq t \}$ belongs to $\mathcal{F}_t$, $\forall t \geq 0$. \\
\indent Let $T$, $S$ be stopping times and $Z$ an integrable $R.V.$. We have:
\begin{enumerate}
	\item $\mathbb{E}[Z|{\mathcal{F}_T}] = \mathbb{E}[Z|{\mathcal{F}_{S \bigwedge T}}]$, P-a.s. on $\{ T \leq S \}$
	\item $\mathbb{E}[\mathbb{E}[Z|{\mathcal{F}_T}]|\mathcal{F}_S] = \mathbb{E}[Z|{\mathcal{F}_{S \bigwedge T}}]$, P-a.s.
\end{enumerate}
\section{Brownian Motion}

\subsection{Construction}

\subsection{Levy Theorem}
Let $M(t), t \geq 0$, be a martingale w.r.t. $\mathcal{F}(t)$. We have $M(0) = 0$, $M(t)$ has continuous sample paths, $\braket{M, M}(t) = t, \forall t \geq 0$.\\ 
$\Longrightarrow M(t)$ is a Brownian motion. \\
\\
\textit{Sketch of Proof:}\\
\\ For any function $f(t, x)$, we have:
\begin{equation}
f(t, M(t)) = f_0 + \int_0^t[f_{t} + \frac{1}{2}f_{xx}]ds + \int_0^t f_x dM(s)
\end{equation}
where we've used $\braket{M, M}(t) =t \rightarrow dM(t)dM(t) = dt$. Taking expectation on both sides, due to the martingale property of $M(t)$, the expectation of the integral w.r.t. $dM(t)$ disappears. Due to the arbitrarity of $f(t, x)$, we can select $f(t, x) = e^{ux - \frac{1}{2}u^2t}$. Thus we obtain:
\begin{subequations}
\begin{align}
f_t + \frac{1}{2}f_{xx} &= 0, \\
\mathbb{E}exp\{uM(t) - \frac{1}{2}u^2 t\} &= e^{0 - 0} = 1, \\
\Longrightarrow \mathbb{E}e^{uM(t)} &= e^{\frac{1}{2}u^2 t}
\end{align}
\end{subequations}
\indent We believe two $R.V.$ who have the same moment fenerating function should have the same distribution. Therefore we prove the normality of $M(t)$.


\subsection{First Passage Time}

\subsection{Maximum of Brownian Motion with Drift}

\section{Ito Integral}
\textbf{Property of $I(t)$: }
\begin{enumerate}
	\item Continuity
	\item $\mathcal{F}(t)-measurable$
	\item Linearity
	\item Martingale
	\item $Isometry:$ $\mathbb{E}I^2(t) = \mathbb{E}\int^t_0{\Delta^2(u) du}$
	\item $QV(t) = [I, I](t) = \int^t_0{\Delta^2(u) du}$ 
\end{enumerate}

\indent There is a useful exercise on Shreve $P_{151} - 4.4.11$.

\section{Risk-Neutral Measure}

\subsection{Change of Measure}
In $(\Omega, \mathcal{F}, \mathbb{P})$, $R.V.$ $Z$ is a.s. nonnegative, $\mathbb{E}Z = 1$.\\
\indent Then for all $A \in \mathcal{F}$, we can define $\widetilde{\mathbb{P}}(A) = \int_A{Z(w)d\mathbb{P}(w)}$.

\subsection{Radon-Nikodym Derivative Process}
We have $(\Omega, \mathcal{F}, \mathbb{P})$ and $filtration$ $\mathcal{F}(t)$ defined on $0 \leq t \leq T$($T$ fixed). $R.V.$ $Z$ is a.s. nonnegative, $\mathbb{E}Z = 1$. Define $\widetilde{\mathbb{P}}$ as in previous subsection.\\
\indent Define the Radon-Nikodym Derivative Process to be $Z(t) = \mathbb{E}[Z|\mathcal{F}(t)]$, $Z(t)$ is a $martingale$ with respect to $\mathcal{F}(t)$.\\
\textbf{Property of $Z(t)$: }
\begin{enumerate}
	\item if $Y$ is a $\mathcal{F}(t)-measurable$ $R.V.$, then $\widetilde{\mathbb{E}}Y = \mathbb{E}[YZ(t)]$
	\item if $0 \leq s \leq t \leq T$, $Y$ is a $\mathcal{F}(t)-measurable$ $R.V.$, then \\$Z(s) \widetilde{\mathbb{E}}[Y|\mathcal{F}(s)] = \mathbb{E}[YZ(t)|\mathcal{F}(s)]$
\end{enumerate}

\subsection{Girsanov Theorem, one dimension}
We have $W(t), 0\leq t \leq T$ on $(\Omega, \mathcal{F}, \mathbb{P})$, and let $\mathcal{F}(t), 0 \leq t \leq T$ be the filtration for $W(t)$ and $\Theta(t)$ be an adapted process to it. Define
\begin{subequations}
\begin{align}
Z(t) &= exp{-\int_0^t\Theta(u)dW(u) - \frac{1}{2}\int_0^t\Theta^2(u) du}, \\
\widetilde{W(t)} &= W(t) + \int_0^t\Theta(u)du, \\
assume &\quad \mathbb{E}\int_0^T \Theta^2(u)Z^2(u)du < \infty
\end{align}
\end{subequations}
Set $Z = Z(T)$, it follows:
\begin{equation}
\mathbb{E}Z = 1 
\end{equation}
Define  a new probability measure by:
\begin{equation}
d\widetilde{\mathbb{P}} = Zd\mathbb{P}
\end{equation}
Then under $\widetilde{\mathbb{P}}$ measure, $\widetilde{W(t)}$ is a Brownian motion.

\subsection{Martingale Representation Theorem, one dimension}
We have $W(t), 0\leq t \leq T$ on $(\Omega, \mathcal{F}, \mathbb{P})$, and let $\mathcal{F}(t), 0 \leq t \leq T$ be the filtration for $W(t)$. Let $M(t)$ be a martingale w.r.t. $\mathcal{F}(t)$. 
$\Longrightarrow \exists$ an $\mathcal{F}(t)$ adapted process $\Gamma(u), 0 \leq u \leq T$, such that:
\begin{equation}
M(t) = M(0) + \int_0^t \Gamma(u)dW(u), 0 \leq t \leq T.
\end{equation}
\indent Using the Martingale Representation Theorem \& Girsanov Theorem, it can be proved that: \\
\indent Let $M(t)$ be a martingale under $\widetilde{\mathbb{P}}$. Then there exists an adapted process $\widetilde{\Gamma(u)}$ w.r.t $\mathcal{F}(t)$, such that:
\begin{equation}
\widetilde{M(t)} = \widetilde{M(0)} + \int_0^t \widetilde{\Gamma(u)} \widetilde{dW(u)}, 0 \leq t \leq T.
\end{equation}

\subsection{Application of Risk-Neutral}

\section{Stochastic Differentiation Equations}

\subsection{Markov Property}

\subsection{Feynmann-Kac Theorem, one dimension}

\subsection{Transitional Density}

\subsection{Kolmogorov Backward \& Forward Equation}
$Shreve$ $P_{291}$\\
\begin{subequations}
Let $\mathcal{A}_t = \beta(t, x)\frac{\partial}{\partial x} + \frac{1}{2} \gamma^2(t, x) \frac{\partial^2}{\partial x^2}$, $\mathcal{A}_t^{\dag} = \beta(t, x)\frac{\partial}{\partial x} - \frac{1}{2} \gamma^2(t, x) \frac{\partial^2}{\partial x^2}$.\\(Note that $t \sim x, T \sim y$) \\
Let the transitional density be $p(t, T, x, y)$.
\begin{align}
(\frac{\partial}{\partial t} + \mathcal{A}_t)p(t, T, x, y) &= 0 \\
(\frac{\partial}{\partial T} - \mathcal{A}_T^{\dag})p(t, T, x, y) &= 0
\end{align}
\end{subequations}
\subsection{Volatility Smile \& Surface}

\section{Excellent Exercise on Courseware}
\subsection{Introduction to SA}
\begin{enumerate}

	\item P.156 the property of infinitismal generator
	\item P.160 Prove the Komogorov  supplem P.55
	\item P.162 Show $V(t, x)$ is the solution to $\partial_t V(t, x) + \mathcal{A}_t V(t, x) + f(t, x) = k(t, x)V(t,x)$ on the previous page.
	\item P.165 top
	\item P.172
	\item P.178
\end{enumerate}

\subsection{Supplementary Notes on Introduction}
\begin{enumerate}
	\item P.26 bottom
	\item P.31
	\item P.50 51
	\item P.53
	\item P.59
\end{enumerate}

\subsection{Application of SA in Financial Engineering}
\begin{enumerate}
	\item P.12 bottom
	\item P.14 prove (3)
	\item P.15 top
	\item P.23 top
	\item P.26 $dX = \sum \Delta_i dSi + r(X - \sum \Delta_i S_i)dt$, prove $d(e^{-rt} X(t)) = \sum \Delta_i d(e^{-rt} S_i(t))$
	\item 
\end{enumerate}




\end{document}
